# ü§ñ Autonomous Agentic Risk Intelligence: Twitter Analysis

## üöÄ The Agentic Evolution
This project demonstrates the transition from manual data monitoring to **Autonomous Risk Discovery**. By leveraging a multi-agent AI architecture, the system automates the identification and prioriti[...]

---
## üéØ Strategic Mission
The system focuses on scaling intelligence:
> **"How can autonomous agents reduce the manual overhead of social media monitoring while maintaining high precision in risk detection?"**

---
## üß† Agent Architecture: The "Hunter-Critic" Governance
The core of this project is a self-reflecting multi-agent system designed to replace static filtering with dynamic reasoning.

### 1. The Risk Intelligence Agent (The "Hunter")
- **Autonomous Role:** Analyzes unstructured tweet datasets for emerging anomalies.
- **Cognitive Task:** Identifies sentiment shifts, geopolitical triggers, and brand risks.
- **Optimization:** Focused on **Recall** to capture all potential high-impact signals.

### 2. The QA & Reflection Agent (The "Critic")
- **Autonomous Role:** Audits findings through Agentic Reflection.
- **Cognitive Task:** Cross-validates findings, reduces potential hallucinations, and assigns a **Severity Score (1-10)**.
- **Optimization:** Focused on **Precision** to ensure results are actionable for decision-makers.

---
## üõ†Ô∏è The Agentic Stack
- **Orchestration:** CrewAI multi-agent framework (sequential process)
- **Intelligence:** Groq-hosted Llama-3.3-70B-Versatile (high-speed cloud inference, free tier sufficient)
- **Dataset:** ChatGPT-related daily tweets (Kaggle public dataset, 5000-tweet sample fully analyzed)
- **Processing:** Batched execution (50 tweets per batch) with checkpointing and automatic rate-limit/daily-limit handling
- **Language:** Python 3.12
- **Data Handling:** Pandas

---
## ‚öôÔ∏è Intelligent Data Engineering
- **Feature Engineering:** Isolation of tweet text and creation timestamps for analysis focus.
- **Temporal Consistency:** Leverages pre-normalized UTC timestamps from raw data.
- **Resilient Execution:** Checkpointing after every batch, automatic pauses for rate limits and daily token caps, safe resume capability.

üî∏ Note: Entire 5000-tweet analysis completed on Groq free tier (no cost incurred). Final report saved as `outputs/risk_report_5000sample_final.csv`.

---
## üìä Process Flow

```mermaid
flowchart TD
    A[Raw CSV data<br/>data/raw/chatgpt_daily_tweets.csv] --> B[Load with Pandas]
    B --> C[Batching Loop<br/>50 tweets per batch]
    C --> D[CrewAI Sequential Crew]
    D --> E[Agent 1: Risk Intelligence<br/>(Hunter - Recall focus)]
    E --> F[Agent 2: QA & Reflection<br/>(Critic - Precision focus)]
    F --> G[Audited Result per Batch]
    G --> H{Checkpoint Saved?<br/>Rate limit handling}
    H -->|Yes| I[Append to results]
    H -->|Rate limit| J[Automatic pause/resume]
    J --> C
    I --> K[All batches complete?]
    K -->|No| C
    K -->|Yes| L[Save final CSV<br/>outputs/risk_report_5000sample_final.csv]
```
